# main.py
from crawler.vietnambiz import crawl_vietnambiz_page, extract_article_content, summarize_content_with_retry
from utils.save_csv import save_to_csv
import time

def main():
    """
    H√†m ch√≠nh ƒëi·ªÅu khi·ªÉn lu·ªìng ch·∫°y c·ªßa ch∆∞∆°ng tr√¨nh.
    """
    all_leads_with_summary = []
    
    # Crawl 1 trang ƒë·ªÉ ki·ªÉm tra (b·∫°n c√≥ th·ªÉ tƒÉng l√™n, v√≠ d·ª• range(1, 4) ƒë·ªÉ crawl 3 trang)
    for page in range(1, 2): 
        url = f"https://vietnambiz.vn/doanh-nghiep/trang-{page}.htm"
        leads = crawl_vietnambiz_page(url)

        for lead in leads:
            print("-" * 50)
            content = extract_article_content(lead['url'])
            
            # Ch·ªâ t√≥m t·∫Øt n·∫øu c√≥ n·ªôi dung
            if content:
                summary = summarize_content_with_retry(content)
                lead["summary"] = summary
                print(f"üìù T√≥m t·∫Øt: {summary[:100]}...") # In ra 100 k√Ω t·ª± ƒë·∫ßu c·ªßa t√≥m t·∫Øt
            else:
                lead["summary"] = "Kh√¥ng th·ªÉ tr√≠ch xu·∫•t n·ªôi dung."
                print("‚ö†Ô∏è  Kh√¥ng th·ªÉ tr√≠ch xu·∫•t n·ªôi dung, b·ªè qua t√≥m t·∫Øt.")
            
            all_leads_with_summary.append(lead)
            
            # Th√™m m·ªôt kho·∫£ng ngh·ªâ ng·∫Øn gi·ªØa c√°c b√†i vi·∫øt ƒë·ªÉ tr√°nh l√†m qu√° t·∫£i server c·ªßa trang web
            time.sleep(1)

    if all_leads_with_summary:
        save_to_csv(all_leads_with_summary)
    else:
        print("\nKh√¥ng thu th·∫≠p ƒë∆∞·ª£c b√†i vi·∫øt n√†o.")

if __name__ == "__main__":
    main()
